{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from unet import UNet, xymDatasetMultiVar\n",
    "import torch\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify directories for data\n",
    "y_var_dir = '../../../data/y_tiles/'\n",
    "x_var_dir = '../../../data/x_tiles/'\n",
    "land_mask_dir = '../../../data/land_mask/'\n",
    "\n",
    "# create the dataset class\n",
    "test_xym = xymDatasetMultiVar(y_var_dir, x_var_dir, land_mask_dir, y_transform=None, x_transform=None, ig_types=['Arson', 'Railroad', 'Powerline'], x_var=['aet-95th', 'aet-mean'], pad_result=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 448, 448]),\n",
       " torch.Size([1, 448, 448]),\n",
       " torch.Size([1, 448, 448]),\n",
       " torch.Size([1, 448, 448]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_xym[0][0].shape, test_xym[1][0].shape, test_xym[2][0].shape, test_xym[3][0].shape,\n",
    "\n",
    "test_xym[0][1].shape, test_xym[1][1].shape, test_xym[2][1].shape, test_xym[3][1].shape,\n",
    "\n",
    "test_xym[0][2].shape, test_xym[1][2].shape, test_xym[2][2].shape, test_xym[3][2].shape,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set up the UNet model\n",
    "## 2 x_var, 3 y_var\n",
    "model = UNet(in_channels=2, n_classes=3, depth=5, wf=6, padding=True, batch_norm=False, up_mode='upconv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## do a sample forward pass\n",
    "test_y = test_xym[0][0]\n",
    "test_x = test_xym[0][1]\n",
    "test_m = test_xym[0][2]\n",
    "test_fwd = model.forward(torch.unsqueeze(test_x,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, torch.float32, torch.float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.dtype, test_y.dtype, test_m.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "## set up a training pass\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "criterion = torch.nn.PoissonNLLLoss(full=True)\n",
    "\n",
    "# set up the dataloader\n",
    "trainloader = torch.utils.data.DataLoader(test_xym, batch_size=4, shuffle=True, num_workers=1)\n",
    "\n",
    "# run through a couple epochs\n",
    "losses = []\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        print(i)\n",
    "        if i>100:\n",
    "            break\n",
    "            \n",
    "        # get the inputs\n",
    "        labels, inputs, mask = data\n",
    "        #print(labels.shape)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        losses.append(loss.item())\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# mask the inputs for loss calculation\n",
    "#loss(torch.masked_select(input=y_hat_tensor, mask = mask_tensor), torch.masked_select(input=y_tensor, mask=mask_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2a03a483e80>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAE9hJREFUeJzt3XuMXOV5x/HvM7O+goGAF0p9iR1qUK0oLWhLkQhpKpLWoMbuJU2NGiVtUaxKoWmUtCoRFY3oXyRqokYiSamCclESQtKmsSqnpErJrS0UkwDBEMPiQNmYYMehhoQYs/bTP87Z9XjZy9jMzuXd70da7cyZ1zPPnhn/9t33vOc9kZlIksrS6HUBkqTOM9wlqUCGuyQVyHCXpAIZ7pJUIMNdkgo0Z7hHxC0RsS8iHpjh8YiID0XEaETcHxEXdb5MSdKJaKfn/nFg0yyPXwFsqL+2AR956WVJkl6KOcM9M78B/HiWJluAT2blTuCMiDi3UwVKkk7cUAeeYxXwRMv9sXrbk7P9o5UrV+a6des68PKStHDcc889P8rM4bnadSLcY5pt065pEBHbqIZuWLt2LTt37uzAy0vSwhERj7fTrhOzZcaANS33VwN7p2uYmTdn5khmjgwPz/mLR5J0kjoR7tuBt9SzZi4BDmbmrEMykqT5NeewTER8FngtsDIixoC/ARYBZOZHgR3AlcAo8Bzwx/NVrCSpPXOGe2ZeNcfjCby9YxVJkl4yz1CVpAIZ7pJUIMNdkgo0cOF+z+NPc+O/fa/XZUhSXxu4cN+19yAf+dqjPH7gp70uRZL61sCF+2UbqpOfvvHIj3pciST1r4EL93VnLWfVGcv41iP7e12KJPWtgQv3iOCyDSv5r0cPMH7kaK/LkaS+NHDhDvDqDSt59tA49//gYK9LkaS+NJDhful5K4mAbznuLknTGshwf9kpi1m/8hR27bXnLknTGchwB7jgnBU8/NRPel2GJPWlgQ33889ZwWMHfsqhF470uhRJ6jsDG+4X/NwKMmF0n713SZpqYMP9/HNWALD7h8/2uBJJ6j8DG+7rzlrO4maDh58y3CVpqoEN96Fmg/POPpXdhrskvcjAhjvABeecysMOy0jSiwx0uG84ZwV7Dx7iJ8+P97oUSeorAx3uq85YBsAPDx7qcSWS1F8GOtzPXrEEgH3PGu6S1Gqww/20Ktz3P/t8jyuRpP4y0OE+vGIpAPueMdwlqdVAh/tpS4dYMtRwWEaSphjocI8Izj5tCfsclpGk4wx0uAOcvWKpwzKSNEUB4b7EYRlJmqKQcLfnLkmtBj/cT1vKs4fGXdddkloMfLgPT5zI5Li7JE0a+HD3LFVJerECwr0+kclxd0maNPjhftrEsIw9d0ma0Fa4R8SmiNgdEaMRce00j6+NiDsi4jsRcX9EXNn5Uqd35vLFDDXCnrsktZgz3COiCdwEXAFsBK6KiI1Tmv01cFtmXghsBT7c6UJn0mgEZyxfxNPPHe7WS0pS32un534xMJqZezLzMHArsGVKmwROq2+fDuztXIlzW7a4yaEXjnbzJSWpr7UT7quAJ1ruj9XbWr0XeHNEjAE7gD+b7okiYltE7IyInfv37z+Jcqe3bFGTnx12nrskTWgn3GOabTnl/lXAxzNzNXAl8KmIeNFzZ+bNmTmSmSPDw8MnXu0Mli1q8jNPYpKkSe2E+xiwpuX+al487HI1cBtAZv43sBRY2YkC27HUcJek47QT7ncDGyJifUQspjpgun1Km/8FLgeIiF+kCvfOjbvMoRpzN9wlacKc4Z6Z48A1wO3AQ1SzYnZFxA0Rsblu9m7gbRFxH/BZ4I8yc+rQzbxZvrjJc465S9KkoXYaZeYOqgOlrduub7n9IHBpZ0tr31IPqErScQb+DFWoDqg6LCNJxxQT7h5QlaRjygj3xVW4d3GYX5L6WhHhvnRRk0x4ftyzVCUJCgn3ZYuaAI67S1KtjHBfXIW74+6SVCkj3Oueu9MhJalSRLgvXWTPXZJaFRHuE8MyjrlLUqWMcJ8clnG2jCRBaeFuz12SgFLC3dkyknScosL9kLNlJAkoJdwdlpGk4xjuklSgIsJ9yVD1Y3gSkyRVigj3RiNYuqhhz12SakWEO9RruttzlySgtHC35y5JQEHhvnSx4S5JE4oJ92WLms5zl6RaUeFuz12SKuWEu8MykjSpmHBf6mwZSZpUTLgvW9R0PXdJqhUT7ssdlpGkScWEu8MyknRMMeG+bHGTQy94JSZJgpLCfVGTw0eOMn7EgJekosId4NC44S5JxYT70kXVj/Lc4fEeVyJJvVdMuA81qx/lyNHscSWS1HtthXtEbIqI3RExGhHXztDmTRHxYETsiojPdLbMuTUbAcD4EcNdkobmahARTeAm4PXAGHB3RGzPzAdb2mwA3gNcmplPR8TZ81XwTJpRhfvRNNwlqZ2e+8XAaGbuyczDwK3Alilt3gbclJlPA2Tmvs6WObeJnrvDMpLUXrivAp5ouT9Wb2t1PnB+RPxnRNwZEZs6VWC7Gg177pI0Yc5hGSCm2TY1QYeADcBrgdXANyPilZn5f8c9UcQ2YBvA2rVrT7jY2UwMyzjNXZLa67mPAWta7q8G9k7T5kuZ+UJmfh/YTRX2x8nMmzNzJDNHhoeHT7bmadWTZRyWkSTaC/e7gQ0RsT4iFgNbge1T2vwL8OsAEbGSaphmTycLnUvDA6qSNGnOcM/MceAa4HbgIeC2zNwVETdExOa62e3AgYh4ELgD+MvMPDBfRU/HA6qSdEw7Y+5k5g5gx5Rt17fcTuBd9VdPTM5zN9wlqZwzVJvOlpGkSeWEezgsI0kTign3yXnuhrsklRPukwdUHZaRpHLCveGwjCRNKibcPaAqSceUE+4uPyBJk8oJ98mTmEx3SSow3HtciCT1gYLCvfrubBlJKijcJxcOc7aMJJUT7i4cJknHFBPuk/PcHZaRpHLCvenyA5I0qZhwH3LJX0maVEy4e4FsSTqmmHB3yV9JOqaYcG84W0aSJhUT7i4cJknHlBPuLhwmSZOKCfdG/ZPYc5ekgsLdA6qSdEw54e48d0maVEy4RwSN8AxVSYKCwh2q3rtry0hSYeHeiLDnLkkUFu7NRnhAVZIoLdzDYRlJgsLCvdFwWEaSoLBwbzbCqZCSRIHh7hmqklRauIcHVCUJSgv3RrhwmCTRZrhHxKaI2B0RoxFx7Szt3hgRGREjnSuxfY2GC4dJErQR7hHRBG4CrgA2AldFxMZp2q0A3gHc1eki2+WwjCRV2um5XwyMZuaezDwM3Apsmabd3wLvAw51sL4T0nD5AUkC2gv3VcATLffH6m2TIuJCYE1m/utsTxQR2yJiZ0Ts3L9//wkXO5emyw9IEtBeuMc02yYTNCIawAeBd8/1RJl5c2aOZObI8PBw+1W2yXnuklRpJ9zHgDUt91cDe1vurwBeCXwtIh4DLgG29+KgatMzVCUJaC/c7wY2RMT6iFgMbAW2TzyYmQczc2VmrsvMdcCdwObM3DkvFc/CJX8lqTJnuGfmOHANcDvwEHBbZu6KiBsiYvN8F3giGs6WkSQAhtpplJk7gB1Ttl0/Q9vXvvSyTo7LD0hSpawzVO25SxJQWLg3GnDU5Qckqaxwr6ZCmu6SVFi4NzjiqIwkFRbugfPcJYnSwt0LZEsSUFi4N8KpkJIEhYW7PXdJqhQV7i75K0mVosLdJX8lqVJWuLvkryQBBYa7PXdJKi3cwzF3SYLCwr3RCI64+oAklRXuzQbOc5ckSgt3l/yVJKCwcG94QFWSgMLCvRlOhZQkKC3cm86WkSQoLdw9Q1WSgNLC3bVlJAkoLNwbEWRCGvCSFriiwr3ZCACnQ0pa8MoMd3vukha4osK9EVW4H3UJAkkLXFHh3qx/mnHTXdICV1i4Vz+O2S5poSsr3KtRGcfcJS14ZYW7s2UkCSgs3Bt1uLvsr6SFrqhwb4Y9d0mCwsK94bCMJAFthntEbIqI3RExGhHXTvP4uyLiwYi4PyK+GhEv73ypc5vouTssI2mhmzPcI6IJ3ARcAWwEroqIjVOafQcYycxXAV8A3tfpQtsxcUDVNd0lLXTt9NwvBkYzc09mHgZuBba0NsjMOzLzufruncDqzpbZnolwd9lfSQtdO+G+Cnii5f5YvW0mVwNffilFnSzXlpGkylAbbWKabdOmZ0S8GRgBfm2Gx7cB2wDWrl3bZontazhbRpKA9nruY8Calvurgb1TG0XE64DrgM2Z+fx0T5SZN2fmSGaODA8Pn0y9szo2LNPxp5akgdJOuN8NbIiI9RGxGNgKbG9tEBEXAv9AFez7Ol9meyYWDnNYRtJCN2e4Z+Y4cA1wO/AQcFtm7oqIGyJic93s/cCpwOcj4t6I2D7D080rh2UkqdLOmDuZuQPYMWXb9S23X9fhuk6Ka8tIUqWoM1QNd0mqlBXunqEqSUBp4W7PXZKAwsK94UlMkgQUFu6TwzL23CUtcGWFu8MykgQUFu4ND6hKElBYuLvkryRVigx3h2UkLXRFhrvDMpIWurLCfXJtmR4XIkk9VlS4N+qfxqmQkha6osLdKzFJUqWscHfJX0kCCgv3hrNlJAkoLNztuUtSpaxwbzoVUpKgtHC35y5JQGnh7mwZSQIKC/eGS/5KElBYuB9bW6bHhUhSjxUV7nW2OywjacErKtwjgkbAkaN23SUtbEWFO8BQo+GwjKQFr7hwbzSc5y5JxYV7M8J57pIWvOLCvdEw3CWpuHBvNsJhGUkLXnnh7rCMJJUX7g7LSFKB4X7qkiEO/PRwr8uQpJ4qLtwvXncmd+05wLiT3SUtYG2Fe0RsiojdETEaEddO8/iSiPhc/fhdEbGu04W267LzV/LMoXHu/8HBXpUgST03Z7hHRBO4CbgC2AhcFREbpzS7Gng6M38B+CBwY6cLbdel560kAr758I96VYIk9Vw7PfeLgdHM3JOZh4FbgS1T2mwBPlHf/gJweUS9/m6XveyUxbxq1el885H9vXh5SeoLQ220WQU80XJ/DPjVmdpk5nhEHATOAnrSfb5swzAf/toor//A13vx8pI0q3dcvoE3/NLPz+trtBPu0/XAp841bKcNEbEN2Aawdu3aNl765PzBr6zhiaef4wUPqkrqQ6cvWzTvr9FOuI8Ba1rurwb2ztBmLCKGgNOBH099osy8GbgZYGRkZN4mo685czl/v/XC+Xp6Sep77Yy53w1siIj1EbEY2Apsn9JmO/DW+vYbgf/IdA0ASeqVOXvu9Rj6NcDtQBO4JTN3RcQNwM7M3A58DPhURIxS9di3zmfRkqTZtTMsQ2buAHZM2XZ9y+1DwO93tjRJ0skq7gxVSZLhLklFMtwlqUCGuyQVyHCXpAJFr6ajR8R+4PGT/Ocr6dHSBnOwrhNjXSemH+vqx5qg7LpenpnDczXqWbi/FBGxMzNHel3HVNZ1YqzrxPRjXf1YE1gXOCwjSUUy3CWpQIMa7jf3uoAZWNeJsa4T04919WNNYF2DOeYuSZrdoPbcJUmzGLhwn+ti3V2sY01E3BERD0XEroj483r7eyPiBxFxb/11ZQ9qeywivlu//s5625kR8e8R8Uj9/WVdrOeClv1xb0Q8ExHv7MW+iohbImJfRDzQsm3afROVD9Wftfsj4qIu1/X+iPhe/dpfjIgz6u3rIuJnLfvto12ua8b3LSLeU++v3RHxm12u63MtNT0WEffW27uyv2bJhN58vjJzYL6olhx+FHgFsBi4D9jYo1rOBS6qb68AHqa6gPh7gb/o8X56DFg5Zdv7gGvr29cCN/bwPfwh8PJe7CvgNcBFwANz7RvgSuDLVFcauwS4q8t1/QYwVN++saWuda3terC/pn3f6s//fcASYH39f7XZrbqmPP53wPXd3F+zZEJPPl+D1nNv52LdXZGZT2bmt+vbzwIPUV1Ltl+1XsT8E8Bv96iOy4FHM/NkT2B7STLzG7z4KmEz7ZstwCezcidwRkSc2626MvMrmTle372T6ipoXTXD/prJFuDWzHw+M78PjFL9n+1qXRERwJuAz87Ha89S00yZ0JPP16CF+3QX6+55oEbEOuBC4K560zX1n1m3dHP4o0UCX4mIe6K6bi3AOZn5JFQfQuDsHtQF1YVcWv/T9Xpfwcz7pp8+b39C1cubsD4ivhMRX4+Iy3pQz3TvW7/sr8uApzLzkZZtXd1fUzKhJ5+vQQv3ti7E3U0RcSrwT8A7M/MZ4CPAecAvA09S/XnYbZdm5kXAFcDbI+I1PajhRaK6TONm4PP1pn7YV7Ppi89bRFwHjAOfrjc9CazNzAuBdwGfiYjTuljSTO9bX+wv4CqO70B0dX9NkwkzNp1mW8f216CFezsX6+6aiFhE9SZ+OjP/GSAzn8rMI5l5FPhH5unP0tlk5t76+z7gi3UNT038yVd/39ftuqh+2Xw7M5+q6+v5vqrNtG96/nmLiLcCvwX8YdYDtfWwx4H69j1UY9vnd6umWd63fthfQ8DvAp+b2NbN/TVdJtCjz9eghXs7F+vuinpc72PAQ5n5gZbtrWNmvwM8MPXfznNdp0TEionbVAflHuD4i5i/FfhSN+uqHdej6vW+ajHTvtkOvKWe1XAJcHDiz+tuiIhNwF8BmzPzuZbtwxHRrG+/AtgA7OliXTO9b9uBrRGxJCLW13X9T7fqqr0O+F5mjk1s6Nb+mikT6NXna76PIHf6i+oI88NUv32v62Edr6b6E+p+4N7660rgU8B36+3bgXO7XNcrqGYs3AfsmthHwFnAV4FH6u9ndrmu5cAB4PSWbV3fV1S/XJ4EXqDqOV09076h+rP5pvqz9l1gpMt1jVKNyU58vj5at/29+r29D/g28IYu1zXj+wZcV++v3cAV3ayr3v5x4E+ntO3K/polE3ry+fIMVUkq0KANy0iS2mC4S1KBDHdJKpDhLkkFMtwlqUCGuyQVyHCXpAIZ7pJUoP8Hm0F5sZ3wKN8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPLEMENT MASKED POISSON LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-fde1c3b3a875>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mmasked_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmasked_select\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mloss_ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion_ma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmasked_y_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmasked_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mloss_ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[0moptimizer_ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\software\\anaconda3\\envs\\eapy_gbdx\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \"\"\"\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\software\\anaconda3\\envs\\eapy_gbdx\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_ma = UNet(in_channels=2, n_classes=3, depth=5, wf=6, padding=True, batch_norm=False, up_mode='upconv')\n",
    "optimizer_ma = optim.Adam(model_ma.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "criterion_ma = torch.nn.PoissonNLLLoss(full=True)\n",
    "\n",
    "# set up the dataloader\n",
    "trainloader_ma = torch.utils.data.DataLoader(test_xym, batch_size=4, shuffle=True, num_workers=1)\n",
    "\n",
    "losses_ma = []\n",
    "for epoch in range(1):  # loop over the dataset one times\n",
    "\n",
    "    for i, data in enumerate(trainloader_ma):\n",
    "        print(i)\n",
    "        if i>100:\n",
    "            break\n",
    "            \n",
    "        # get the inputs\n",
    "        labels, inputs, mask = data\n",
    "        mask = mask.byte()\n",
    "        #print(labels.shape)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer_ma.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model_ma(inputs)\n",
    "        \n",
    "        # masked loss\n",
    "        masked_y_hat = torch.masked_select(input=outputs, mask=mask)\n",
    "        masked_labels = torch.masked_select(input=labels, mask=mask)\n",
    "        loss_ma = criterion_ma(masked_y_hat, masked_labels)\n",
    "        loss_ma.backward()\n",
    "        optimizer_ma.step()\n",
    "        \n",
    "        losses_ma.append(loss_ma.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_ma.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEBUG STUFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for i in range(len(test_xym)):\n",
    "#     print(i, test_xym[i][2].shape)\n",
    "import glob, os, rasterio\n",
    "files = glob.glob(r'C:\\Projects\\wildfire_nate\\data\\tile_tifs\\*.tif')\n",
    "\n",
    "for fi in files:\n",
    "    with rasterio.open(fi) as src:\n",
    "        shp = src.read().shape\n",
    "        if (shp[1] != 448) | (shp[2] != 448):\n",
    "            print(os.path.basename(fi), shp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(r'C:\\Projects\\wildfire_nate\\data\\tile_tifs\\*.tif')\n",
    "new_path = r'C:\\Projects\\wildfire_nate\\data\\tile_tifs\\new'\n",
    "if not os.path.exists(new_path):\n",
    "    os.mkdir(new_path)\n",
    "\n",
    "for fi in files:\n",
    "    with rasterio.open(fi) as src:\n",
    "        profile = src.profile\n",
    "        arr = src.read()\n",
    "        arr *= 0\n",
    "        arr += int(os.path.basename(fi).split('.')[0][1:])\n",
    "        \n",
    "    dest_fi = os.path.join(new_path, os.path.basename(fi))\n",
    "    with rasterio.open(dest_fi, 'w', **profile) as dest:\n",
    "        dest.write(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_fi = r'C:\\Projects\\wildfire_nate\\data\\tiles\\tiles.shp'\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "tiles_df = gpd.read_file(tile_fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make a temp column to store image dims\n",
    "tiles_df['temp'] = 0\n",
    "\n",
    "# set a 'good dimension' variable\n",
    "good_dims = 448*448\n",
    "\n",
    "# iterate through the tiles\n",
    "names = tiles_df.Name\n",
    "for i,name in enumerate(names):\n",
    "    raster_fi = os.path.join(r'C:\\Projects\\wildfire_nate\\data\\tile_tifs', f'{name}.tif')\n",
    "    with rasterio.open(raster_fi) as src:\n",
    "        shp = src.read().shape\n",
    "        dims = shp[1]*shp[2]\n",
    "        \n",
    "        if dims != good_dims:\n",
    "            tiles_df.iloc[i, tiles_df.columns.get_loc('temp')] = 1\n",
    "#             df.iloc[0, df.columns.get_loc('COL_NAME')] = x\n",
    "        \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tiles_df.temp.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_df.plot(column='temp', alpha=0.4, figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (eapy_gbdx)",
   "language": "python",
   "name": "eapy_gbdx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
